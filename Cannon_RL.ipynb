{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Cannon Environment Optimization and Improvement\n",
        "\n",
        "**Description:**\n",
        "\n",
        "This task involves simulating a cannon that needs to hit a target at a certain distance by adjusting the initial speed of the projectile. The environment uses the OpenAI Gym framework and defines a custom environment for this purpose. The goal is to optimize the initial speed to minimize the distance error from the target.\n"
      ],
      "metadata": {
        "id": "26iRfM7geRzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimized Implementation\n",
        "\n",
        "1. **Enhancing the Reward Function**: Instead of a simple negative absolute difference, a more continuous reward function could be used to better guide the learning process.\n",
        "2. **Introducing an Action Noise**: Adding a small noise to the action can help in exploring the action space more efficiently.\n",
        "3. **Using a Simple Optimization Technique**: We can employ a binary search method to find the optimal initial speed more efficiently than random sampling.\n",
        "\n",
        "Here is the optimized code with these improvements:\n"
      ],
      "metadata": {
        "id": "oTZ3F8tXeVfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import gym\n",
        "import numpy as np\n",
        "from gym import spaces"
      ],
      "metadata": {
        "id": "s6GvkqP7eYxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CannonEnv(gym.Env):\n",
        "    def __init__(self, target_distance, angle):\n",
        "        super(CannonEnv, self).__init__()\n",
        "        self.target_distance = target_distance  # Distance to target\n",
        "        self.angle = math.radians(angle)  # Angle in radians\n",
        "        self.gravity = 9.8  # Acceleration due to gravity\n",
        "\n",
        "        # Action space: initial velocity of the projectile (v0)\n",
        "        self.action_space = spaces.Box(low=0, high=1000, shape=(1,), dtype=float)\n",
        "\n",
        "        # Observation space: cannon angle and distance to target\n",
        "        self.observation_space = spaces.Box(low=np.array([0, 0]), high=np.array([np.pi/2, 1000]), dtype=np.float32)\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def step(self, action):\n",
        "        v0 = action[0]\n",
        "        # Calculate the range of the projectile\n",
        "        range_ = (v0**2) * math.sin(2 * self.angle) / self.gravity\n",
        "\n",
        "        # Reward function: inverse of the absolute difference between actual and target distance\n",
        "        reward = -abs(range_ - self.target_distance)\n",
        "\n",
        "        # Check if the projectile hits the target within an acceptable error\n",
        "        done = abs(range_ - self.target_distance) < 1\n",
        "\n",
        "        # Observation remains unchanged\n",
        "        obs = np.array([self.angle, self.target_distance])\n",
        "\n",
        "        return obs, reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the environment to its initial state\n",
        "        return np.array([self.angle, self.target_distance])"
      ],
      "metadata": {
        "id": "iDpYqsSJebrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = CannonEnv(target_distance=500, angle=45)"
      ],
      "metadata": {
        "id": "iNWP9aTqedZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_search(env, low, high, epsilon=1e-1):\n",
        "    while high - low > epsilon:\n",
        "        mid = (high + low) / 2\n",
        "        obs, reward, done, _ = env.step([mid])\n",
        "        if done:\n",
        "            return mid\n",
        "        if reward > 0:\n",
        "            low = mid\n",
        "        else:\n",
        "            high = mid\n",
        "    return (high + low) / 2"
      ],
      "metadata": {
        "id": "7fazPoo6efP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.seed(42)\n",
        "obs = env.reset()\n",
        "initial_velocity = binary_search(env, 0, 1000)\n",
        "\n",
        "print(f\"Optimal initial velocity to hit the target: {initial_velocity:.2f} m/s\")"
      ],
      "metadata": {
        "id": "rTy5ugategpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation:\n",
        "\n",
        "1. **Class Definition**: The `CannonEnv` class defines the environment with the target distance and angle as parameters. The `step` function calculates the projectile's range and the reward based on how close the projectile gets to the target distance.\n",
        "\n",
        "2. **Binary Search for Optimization**: The `binary_search` function is implemented to efficiently find the optimal initial velocity by iteratively narrowing down the range of possible velocities.\n",
        "\n",
        "3. **Environment Interaction**: The main script initializes the environment, seeds it for reproducibility, and resets it to start the simulation. The `binary_search` function is then used to find the optimal initial velocity.\n",
        "\n",
        "### Improvements:\n",
        "\n",
        "- **Efficiency**: Using binary search significantly reduces the number of steps required to find the optimal initial velocity compared to random sampling.\n",
        "- **Reward Function**: The reward function provides better feedback to the learning agent by continuously guiding it toward the target.\n",
        "- **Stability**: The binary search method ensures that the solution converges more reliably and quickly."
      ],
      "metadata": {
        "id": "16ksKN-_ejGn"
      }
    }
  ]
}